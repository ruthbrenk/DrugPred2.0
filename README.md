# DrugPred2.0
Python scripts that were used to run DrugPred2.0 as described in our PLOS One paper

You will also need Python libraries from Openeye and Simca from Umetrics to carry out DrugPred calculations. You will also need DOCK 3.6 for the calculations.
The current version of the code only works if you also have a MySQL db in which you store information about the files that should be processed and into which the calculated desribitor values will be stored.



1. Note that this program  are highly specialized for running parallel calculations because of complexities in handling protein homologs. Appropriate changes will be required when using them for different purposes.

2. Your data must be arranged in an appropriate directory tree. You have to prepare separate directories for each PA code that needed to be analysed. Each of these were named in a similar format such as PA1234, i.e. had 6 letters in its name and started with a PA. Do not put any other directories in your analysis directory that also has 6-letter names starting with PA or this code might fail. Under each PA directory, you can place as many PDB files as you like (each is a homolog of the appropriate PA code) and run the DrugPred program. It does everything automatically. See syntax below.

3. The regular DrugPred constraints apply even now, i.e., the PDB files should not have more than 10,000 lines and no more than 1 instance of the ligand demarcating the binding pocket. The PA code and PDB id, along with ligand, cofactor and metal (3-letter codes from the PDB file) must be uploaded into a MySQL table, which we will call MyDS for the sake of this example. A table with appropriate fields for descriptors must also be prepared, which we will call MyDescriptors here. 

4. Once all these things are prepared, you may run the program on a cluster with the following syntax: “RunInEachPADirectory.py DatabaseName MyDS MyDescriptors Username Password”. This will carry out all operations required for superligand preparation and descriptor calculation on the cluster. All data will be uploaded onto the MyDescriptors table in the database.

5. Please note that the data obtained from MyDescriptors is not appropriate for use directly in SIMCA-P+ because of its complexities (e.g. you have to create unique ID fields before importing into SIMCA-P+ so duplicate PDB ids homologous to different PA codes can be distinguished from each other, or else SIMCA-P+ overwrites data. My strategy was simply to introduce a separator between the PA code, PDB code and ligand name to create unique identifiers, e.g. PA1234_1abc_ABC before importing into SIMCA-P+)


Using Simca:

1. Use an appropriate MySQL command to obtain the correct data, which must include the following descriptors: id, csa, hsa_t, psa_r, hiaa, haa, dsasa.  If it tells you that a secondary observation is missing and wants to generate it automatically, allow it to do so. This will not change anything in your scoring.

2. Open the SIMCA file in the repro

3. Download a file from MySQL in appropriate format (Excel or CSV), which is  recognized by SIMCA-P+ and use the “file>>import secondary dataset” option under the main SIMCA-P+ menu to import the data into the program. Here, you can select the first row as column titles. That row is now excluded from the data, and is used as descriptor names. 

4. Once the secondary dataset is generated inside SIMCA-P+, you must select an appropriate dataset to run predictions/DModX calculations on. This is done by accessing “predictions>>specify dataset>>specify” and selecting appropriate options in the menu that appears.

5.  Next, you can go to “predictions>>distance to model>>x-block>>column plot” to get the DModX values. The plot that appears can be converted into a list by right clicking on it and selecting appropriate options. Same is true for any plot generated by SIMCA=P+.

6. You can obtain scores for all rows in  your data by using the “predictions>>Y-predicted>>column plot” option under the main menu.

We also have a more streamlined version of the code which was produced after the data in the PLOS ONE paper was generated. Please contact us if you are interested in this version.
If you are intersted in only a small number of predictions we are more than happy to carry out the calculations for you. Don't hesitate to contact us.


